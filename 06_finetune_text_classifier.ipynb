{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39973ed4",
   "metadata": {},
   "source": [
    "# Fine-Tune a Text Classifier with Transformers\n",
    "This notebook demonstrates how to fine-tune a pretrained DistilBERT model on the IMDb sentiment dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8411305a",
   "metadata": {},
   "source": [
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f209d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54611ff3-6337-4315-9a14-b87028892733",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda05711-37f7-4635-842d-811e9429355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa2776d",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56fe5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "print('--------------------')\n",
    "import transformers\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ef4ac3",
   "metadata": {},
   "source": [
    "## Load IMDb Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148d7680",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('imdb')\n",
    "train_data = dataset['train'].shuffle(seed=42).select(range(2000))  # Smaller subset for quick training\n",
    "test_data = dataset['test'].shuffle(seed=42).select(range(500))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d0ccc8",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Tokenize the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99fdbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], padding='max_length', truncation=True)\n",
    "\n",
    "train_enc = train_data.map(tokenize_function, batched=True)\n",
    "test_enc = test_data.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6594e9cc",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ea2046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1befa6",
   "metadata": {},
   "source": [
    "## Define Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ea197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(labels, preds),\n",
    "        'f1': f1_score(labels, preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735bbd06",
   "metadata": {},
   "source": [
    "## Set Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e70b06-2406-462d-b93d-e1809747fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import transformers; print(transformers.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e59180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=2,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba0b51",
   "metadata": {},
   "source": [
    "## Initialize Trainer and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_enc,\n",
    "    eval_dataset=test_enc,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b13125",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185cc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9799764",
   "metadata": {},
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b5061",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./sentiment-model\")\n",
    "tokenizer.save_pretrained(\"./sentiment-model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3a3b7-ab6d-4010-86c7-bd1fc6a1ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datasets import load_dataset\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load IMDb dataset\n",
    "# dataset = load_dataset('imdb')\n",
    "\n",
    "# # Convert to DataFrames\n",
    "# train_df = pd.DataFrame(dataset['train'])\n",
    "# test_df = pd.DataFrame(dataset['test'])\n",
    "\n",
    "# # Save using tab as separator\n",
    "# train_df.to_csv('train.tsv', sep='\\t', index=False)\n",
    "# test_df.to_csv('test.tsv', sep='\\t', index=False)\n",
    "\n",
    "# print(\"Saved as 'train.tsv' and 'test.tsv' with tab separators.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54e121-2cc5-453b-88d4-a8def19ca1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Arabic Sentiments dataset\n",
    "dataset = load_dataset(\"ImranzamanML/Arabic-Sentiments\")\n",
    "\n",
    "# # Convert to pandas DataFrames\n",
    "# train_df = pd.DataFrame(dataset[\"train\"])\n",
    "# test_df = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# # Optional: Save locally as TSV\n",
    "# train_df.to_csv(\"arabic_train.tsv\", sep=\"\\t\", index=False)\n",
    "# test_df.to_csv(\"arabic_test.tsv\", sep=\"\\t\", index=False)\n",
    "\n",
    "# print(\"âœ… Saved: arabic_train.tsv and arabic_test.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d804ced4-bd0f-4acf-95b1-26c6ce004c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15d11fa",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- We fine-tuned a DistilBERT model on a subset of the IMDb dataset.\n",
    "- We used Hugging Face `Trainer` for easy training and evaluation.\n",
    "- The model is saved locally and ready for deployment or inference."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
